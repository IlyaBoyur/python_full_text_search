# Шпоргалка Elasticsearch
- **Стемминг** — это нахождение основы слова для заданного исходного слова. Основа необязательно совпадает с морфологическим корнем слова.
- **Лемматизация** — приведение слова к нормальной (словарной) форме. Для существительных это именительный падеж и единственное число.
- **Корпус** — в лингвистике корпусом называется совокупность текстов, собранных в соответствии с определенными принципами, размеченных по определенному стандарту и обеспеченных специализированной поисковой системой. Это может быть и разделение по стилям и жанрам, разделение по эпохе написания, по форме написания.
- **Параллельный корпус** — это один или более текстов на двух языках, сопоставленные между собой парами, когда в каждой паре оба предложения несут один и тот же смысл.
- **Стоп-слова, или шумовые слова,** — предлоги, суффиксы, междометия, цифры, частицы и подобное. Общие шумовые слова всегда исключаются из поискового запроса (кроме поиска по строгому соответствию поисковой фразы), также они игнорируются при построении инвертированного индекса.
- **N-грамма** — последовательность из N элементов. С семантической точки зрения это может быть последовательность звуков, слогов, слов или букв.


## Примеры работы с Kibana Dev Tools 
```bash
# Подготовка: Создать индекс
PUT /table
{
  "mappings": {
    "properties": {
      "text_field": {"type": "keyword"},
      "number": {"type": "long"}
    }
  }
}
# Подготовка: Добавить документы
POST /table/_doc/
{"text_field": "my pretty text", "number": 15}
# Получить данные по идентификатору
GET /table/_doc/-gEW940BVK3mpl69nyKn
# Обновить данные по идентификатору
POST /table/_doc/-gEW940BVK3mpl69nyKn
{"text_field": "my pretty text", "number": 16}
# Использование: Искать по условиям фильтрации
GET /table/_search
{"query": {"bool": {"filter": [{"range": {"number": {"gt": 10}}}]}}}
# Искать с помощью движка SQL
# (table в кавычках - это служебное слово для SQL-запросов в Elasticsearch)
POST /_sql?format=txt
{"query": """SELECT * FROM "table" WHERE number > 10"""}
# Перевести SQL в язык запросов Elasticsearch
POST /_sql/translate
{"query": """SELECT * FROM "table" WHERE number > 10"""}
# Проверить существует ли запись
HEAD my-index-000001/_doc/0
```



## Движок Elasticsearch
Любые данные, которые попадают в индекс, предварительно обрабатываются анализатором.  
Именно получившиеся токены попадут в индекс.  
Чтобы искать по таким данным, нужно привести поисковый запрос к такому же формату, т.е. прогнать через тот же анализатор.  

1. [CharFilters](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-charfilters.html)  
изменяет исходную строку целиком (н-р, вырезает конкретные слова, слова по шаблону, HTML тэги и т.д.)
1. [Tokenizer](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-tokenizers.html)  
разбивает исходную строку на токены (н-р, по пробелам и символам пунктуации)
1. [Token FIlters](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-tokenfilters.html)  
обрабатывает каждый тэг в отдельности (н-р, приводит к нижнему регистру, стемминг и др.)


## Ранжирование результатов запросов
Для ранжирования нужно рассчитать, насколько документ релевантен запросу.


### Метрика [TF-IDF](https://ru.wikipedia.org/wiki/TF-IDF)
- используется абсолютно во всех поисковых системах как один из компонентов
- большинство доступных библиотек опираются на неё как на основную

TF (Term Frequency) — отношение числа вхождений некоторого слова к общему числу слов документа. Например, если слово «котик» встречается 5 раз в документе на 100 слов, то TF = 0.05  
IDF (Inverse Document Frequency) — это обратная частотность документов, которая измеряет важность термина. Уменьшает весь общеупотребительных слов, предлогов, союзов, междометий. Считается как логарифм от общего количества документов, делённого на количество документов, в которых встречается искомый термин. Например, если «котик» содержится в 1000 документах из 10 000 000 документов, то IDF будет равной: log(10 000 000/1000) = 4.  
Для расчета окончательного значения веса слова необходимо TF умножить на IDF. В данном примере, TF-IDF вес для слова «котик» в выбранном документе будет равен: 0,05 × 4 = 0,2.  
Чем больше «важных» слов из запроса входит в определённый документ, тем он более релевантен.

## Полная схема поиска
1. Обрабатываем поисковый запрос анализатором, который используется в индексе.
1. Достаём все документы, соответствующие запросу.
1. Считаем необходимые метрики.
1. Сортируем результаты запроса по рассчитанным метрикам.


## Поиск по совпадению
```
curl -XGET http://127.0.0.1:9200/<index_name>/_search -H 'Content-Type: application/json' -d '{
  "query": {"bool": {"must": [{"match": {"<field_name>": "<query>"}}]}}
}'
```
`query` — главный ключ, с помощью которого вы говорите ES, что нужно искать.  
`bool` — это тип запроса. Построен с использованием одного или нескольких логических предложений, каждое из которых имеет типизированное вхождение.  

Типы событий:
- `must` — возвращённые данные обязательно должны соответствовать правилу, которое описано в этом ключе.  
- `must_not` — возвращённые данные не должны соответствовать правилу, описанному в этом ключе.  
- `filter` — похож на must, но с одним отличием. Найденные с помощью этих правил совпадения не будут участвовать в расчёте релевантности.
- `should` — возвращаемые данные обязательно должны соответствовать хотя бы одному правилу, которое описано в этом ключе. Он работает как ИЛИ для всех описанных внутри ключа правил.  

`matсh` — это описание действия, сам поиск.

Первый поисковый запрос к полю с типом `text` будет долгим - так работает ленивая загрузка в ES. Чтобы Elasticsearch перестраивал индекс, можно сделать одну из двух вещей:
1. Обновлять индекс вручную:
```
curl http://127.0.0.1:9200/_refresh
```
2. Попросить Elasticsearch обновлять индекс с некоторой
периодичностью, например, каждую секунду:
```
curl -XPUT http://127.0.0.1:9200/<index_name>/_settings -H 'Content-Type: application/json' -d '{
  "refresh_interval": "1s"
}'
```
Всегда нужно помнить, что обновление индекса занимает время, а главное — тормозит загрузку данных.


## Нечеткий поиск
```
curl -XGET http://127.0.0.1:9200/<index_name>/_search -H 'Content-Type: application/json' -d '{
  "query": {
    "match": {
      "text_field": {
      "query": "whit code",
      "fuzziness": "auto"
      }
    }
  }
}'
```

## Поиск для русского языка
Для подключения русского языка необходимо _задать настройки анализатора при создании индекса_.  
Для улучшения поиска достаточно добавить стеммер и **стоп-слова** (массив слов, которые ES будет игнорировать при индексации.
Чаще всего он состоит из предлогов и частиц):
```
curl -XPUT http://127.0.0.1:9200/table3 -H 'Content-Type: application/json' -d '{
    "settings": {
        "refresh_interval": "1s",
        "analysis": {
            "filter": {
                "russian_stop": {"type": "stop", "stopwords": "_russian_"},
                "russian_stemmer": {"type": "stemmer", "language": "russian"},
            },
            "analyzer": {
                "ru": {
                    "tokenizer": "standard",
                    "filter": ["lowercase", "russian_stop", "russian_stemmer"],
                }
            },
        },
    },
    "mappings": {
        "dynamic": "strict",
        "properties": {
            "text_field": {"type": "text", "analyzer": "ru"},
            "number": {"type": "long"},
        },
    },
}'
```