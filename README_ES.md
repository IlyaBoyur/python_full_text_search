# Шпоргалка Elasticsearch

## Примеры работы с Kibana Dev Tools 
```bash
# Подготовка: Создать индекс
PUT /table
{
  "mappings": {
    "properties": {
      "text_field": {"type": "keyword"},
      "number": {"type": "long"}
    }
  }
}
# Подготовка: Добавить документы
POST /table/_doc/
{"text_field": "my pretty text", "number": 15}
# Сохранить данные по идентификатору
GET /table/_doc/-gEW940BVK3mpl69nyKn
# Обновить данные по идентификатору
POST /table/_doc/-gEW940BVK3mpl69nyKn
{"text_field": "my pretty text", "number": 16}
# Использование: Искать по условиям фильтрации
GET /table/_search
{"query": {"bool": {"filter": [{"range": {"number": {"gt": 10}}}]}}}
# Искать с помощью движка SQL
# (table в кавычках - это служебное слово для SQL-запросов в Elasticsearch)
POST /_sql?format=txt
{"query": """SELECT * FROM "table" WHERE number > 10"""}
# Перевести SQL в язык запросов Elasticsearch
POST /_sql/translate
{"query": """SELECT * FROM "table" WHERE number > 10"""}
# Проверить существует ли запись
HEAD my-index-000001/_doc/0
```



## Движок Elasticsearch
Любые данные, которые попадают в индекс, предварительно обрабатываются анализатором.  
Именно получившиеся токены попадут в индекс.  
Чтобы искать по таким данным, нужно привести поисковый запрос к такому же формату, т.е. прогнать через тот же анализатор.  

1. [CharFilters](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-charfilters.html)  
изменяет исходную строку целиком (н-р, вырезает конкретные словаб слова по шаблону, HTML тэги и т.д.)
1. [Tokenizer](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-tokenizers.html)  
разбивает исходную строку на токены (н-р, по пробелам и символам пунктуации)
1. [Token FIlters](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-tokenfilters.html)  
обрабатывает каждый тэг в отдельности (н-р, приводит к нижнему регистру, стемминг (т.е. выделение неизменяемой при склонении части) и др.)


## Ранжирование результатов запросов
Для ранжирования нужно рассчитать, насколько документ релевантен запросу.


### Метрика [TF-IDF](https://ru.wikipedia.org/wiki/TF-IDF)
- используется абсолютно во всех поисковых системах как один из компонентов
- большинство доступных библиотек опираются на неё как на основную
TF (Term Frequency) — отношение числа вхождений некоторого слова к общему числу слов документа.  
IDF (Inverse Document Frequency) — это обратная частотность документов, которая измеряет важность термина.

## Запрос
query — главный ключ, с помощью которого вы говорите ES, что нужно искать.  
bool — это тип запроса. Построен с использованием одного или нескольких логических предложений, каждое из которых имеет типизированное вхождение  

Типы событий:
- must — возвращённые данные обязательно должны соответствовать правилу, которое описано в этом ключе.
- must_not — возвращённые данные не должны соответствовать правилу, описанному в этом ключе.
- filter — похож на must, но с одним отличием. Найденные с помощью этих правил совпадения не будут участвовать в расчёте релевантности.
- should — возвращаемые данные обязательно должны соответствовать хотя бы одному правилу, которое описано в этом ключе. Он работает как ИЛИ для всех описанных внутри ключа правил.
matсh — это описание действия, сам поиск.

